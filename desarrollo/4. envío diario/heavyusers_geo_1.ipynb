{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "437f3e0a-d60d-4840-be75-247bd3b4933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0576791-3793-470a-a749-13b1bb8cff67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DarioAlejandroLatorr\\\\OneDrive\\\\claro_20_abril_2021\\\\ENVIO_DARIO\\\\TRONCALES_HEAVYUSERS_DATAGEO'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium as fl\n",
    "from folium import plugins\n",
    "import geopandas as gpd\n",
    "import webbrowser\n",
    "\n",
    "from Priorizacion_funciones.heavyusers_funs import *\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans, MeanShift\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8e027-03a7-4fb0-949a-ecf60d8c2e37",
   "metadata": {},
   "source": [
    "# MANZANAS CON NOMBRE DE MUNICIPIO/CIUDAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42716e1d-18eb-406f-8caa-899e3fdd8528",
   "metadata": {},
   "source": [
    "La siguiente línea no es necesaria correrla si ya existe el archivo MGN_URB_MANZANA_NOM_MUNICIPIO.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d176438-53c8-4855-8dc0-9c50b7c1f0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_manzana_nom_mun =  gpd.read_file('Data_geo\\MANZANA\\MGN_URB_MANZANA.shp')\n",
    "shap_politico_nom_mun =  gpd.read_file('Data_geo\\ADMINISTRATIVO\\MGN_MPIO_POLITICO.shp')[['DPTO_CCDGO','MPIO_CCDGO','MPIO_CNMBR']]\n",
    "shap_politico_nom_mun['COD_MPIO'] = shap_politico_nom_mun['DPTO_CCDGO'] + shap_politico_nom_mun['MPIO_CCDGO']\n",
    "shap_manzana_nom_mun = shap_manzana_nom_mun.merge(shap_politico_nom_mun, on='COD_MPIO', how='left')\n",
    "\n",
    "dic_vocales = {'Á':'A','É':'E','Í':'I','Ó':'O','Ú':'U'}\n",
    "def quit_tildes(ciudad):\n",
    "    for voc_til in dic_vocales.keys():\n",
    "        ciudad = ciudad.replace(voc_til,dic_vocales[voc_til])\n",
    "    return ciudad\n",
    "shap_manzana_nom_mun['CIUDAD'] = [quit_tildes(ciudad) for ciudad in  shap_manzana_nom_mun['MPIO_CNMBR']]\n",
    "\n",
    "shap_manzana_nom_mun.to_file('Data_geo\\MANZANA\\MGN_URB_MANZANA_NOM_MUNICIPIO.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e10520f-face-4f01-ae0f-2d4308764f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.4844560623169"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "name_file = 'USERS_CLASIFICADOS_COMPLETO.CSV'\n",
    "list_columns =['CUENTA','CUENTA_MATRIZ', 'NODO',\n",
    "                   'CIUDAD', 'LATITUD','LONGITUD', \n",
    "                   'flbb_down_traffic_bytes','flbb_up_traffic_bytes',\n",
    "                   'traf_total']\n",
    "path_he_us = f'Datos_heavy_users/{name_file}'\n",
    "path_manzanas = 'Data_geo\\MANZANA\\MGN_URB_MANZANA_NOM_MUNICIPIO.shp'\n",
    "    \n",
    "df_users = pd.read_csv(path_he_us, sep='|')[list_columns]\n",
    "shape_manzanas = gpd.read_file(path_manzanas)[['CIUDAD','geometry']]\n",
    "time.time() -t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c11e111a-cc6a-4149-ab1a-e8e20553bc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.337045669555664"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "path_ = 'Data_geo/HEAVYUSERS_ANALISIS/'\n",
    "ciudad = 'PASTO'\n",
    "# todos los nodos de la ciudad\n",
    "nodos_ciudad = df_users.loc[df_users['CIUDAD']==ciudad,'NODO'].unique()\n",
    "# nodos de prueba\n",
    "nodos_ciudad = ['PCN','JDS','LCD']\n",
    "lim_coord_atipica = 0.03 # aprox 3 km\n",
    "percentil = 90  # de momento se consideran heavy users a los usuarios con el tráfico total superior al del percentil\n",
    "# ancho de banda relacionado con las distancias \n",
    "ban_list = np.arange(0.0006,0.0010,0.0001)\n",
    "# 0.0009  aprox 100 metros https://www.usna.edu/Users/oceano/pguth/md_help/html/approx_equivalents.htm\n",
    "\n",
    "# limite de usuarios los valores pueden ser modificados el límite es l número de puertos aunque según indicaciones siempre\n",
    "# se dejan algunos libres para nuevos clientes.\n",
    "lim_usuarios_list = np.array([32,64,100])\n",
    "incluir_cuentas_matriz = True\n",
    "incluir_cuentas_horizontales = False\n",
    "\n",
    "#######################################################################################\n",
    "list_ari_cuadra = ['LONGITUD_CENTER_ARISTA_CUADRA','LATITUD_CENTER_ARISTA_CUADRA']\n",
    "colors_list = ['lightblue', 'red', 'black', 'green',  'blue', 'orange','darkblue',\n",
    "                       'cadetblue', 'pink', 'lightgreen', 'gray', 'darkred', 'purple',\n",
    "                       'lightblue', 'red', 'black', 'green',  'blue', 'orange','darkblue',\n",
    "                       'cadetblue', 'pink', 'lightgreen', 'gray', 'darkred', 'purple']\n",
    "create_dir(f'{path_}{ciudad}')\n",
    "# listas para dataframe info\n",
    "for nodo in nodos_ciudad:\n",
    "    try:\n",
    "        # alistando capas, guardando archivos \n",
    "\n",
    "        df_usuarios, shape_ciudad = get_data(df_users, shape_manzanas, ciudad, nodo,\n",
    "                                                     incluir_cuentas_matriz=incluir_cuentas_matriz,\n",
    "                                                     incluir_cuentas_horizontales=incluir_cuentas_horizontales)\n",
    "        l_df_usuarios_ini = len(df_usuarios)\n",
    "\n",
    "        df_usuarios_analisis = drop_users_far_center(df_usuarios, lim_atipica = lim_coord_atipica)\n",
    "        df_usuarios_analisis = prep_and_save_datageo(df_usuarios_analisis, shape_ciudad, path_, ciudad, nodo)\n",
    "\n",
    "        trafi_total_usuarios_analisis = df_usuarios_analisis[\"traf_total\"].sum()\n",
    "        \n",
    "        # seleccionando a los heavyusers\n",
    "        hu_treshold = np.percentile(df_usuarios_analisis['traf_total'], percentil)\n",
    "        df_hu = df_usuarios_analisis[df_usuarios_analisis['traf_total']>=hu_treshold].copy()\n",
    "\n",
    "        #guardando archivos\n",
    "        path_nodo = f'{path_}/{ciudad}/{nodo}'\n",
    "        save_csv(df_usuarios, f'{path_nodo}/all_users.csv')\n",
    "        df_usuarios_analisis_pre_pro = df_usuarios_analisis.copy()\n",
    "        save_csv(df_hu, f'{path_nodo}/heavy_users.csv')\n",
    "\n",
    "\n",
    "        # creando y guardando mapa de los usuarios para el análisis.\n",
    "        df_no_hu = df_usuarios_analisis[df_usuarios_analisis['traf_total']<hu_treshold]\n",
    "        create_map_users(df_no_hu, df_hu, path_nodo)\n",
    "        for ban in ban_list:\n",
    "            for lim_usuarios in lim_usuarios_list:\n",
    "                \n",
    "                path_folder = f'{path_nodo}/dist_aprox_{int(ban*100/0.0009)}_lim_usuarios_{lim_usuarios}'\n",
    "                create_dir(path_folder)\n",
    "\n",
    "\n",
    "                # haciendo clusters\n",
    "                clu_meanshift = MeanShift(bandwidth=ban, cluster_all=False)\n",
    "                ## el ajuste se hace con los heavyusers\n",
    "                X = df_hu[list_ari_cuadra]\n",
    "                clu_meanshift.fit(X)\n",
    "                ## la predicción se hace con todos los usuarios del análisis\n",
    "                X_pred = df_usuarios_analisis[list_ari_cuadra].values\n",
    "                df_usuarios_analisis['CLUSTER'] = clu_meanshift.predict(X_pred)\n",
    "\n",
    "                # excluyendo usuarios que no fueron clusterizados\n",
    "                mask_con_cluster = (df_usuarios_analisis['CLUSTER']!=-1)\n",
    "\n",
    "                df_usuarios_analisis_clusterizados = df_usuarios_analisis[mask_con_cluster].copy()\n",
    "\n",
    "                # rankenado usuarios y escogiendo para los clusters\n",
    "                df_usuarios_analisis_clusterizados['rank'] = df_usuarios_analisis_clusterizados.groupby('CLUSTER')[\"traf_total\"].rank(ascending=False)\n",
    "                mask_usuarios_max = (df_usuarios_analisis_clusterizados['rank']<=lim_usuarios)\n",
    "                df_usuarios_analisis_clusterizados = df_usuarios_analisis_clusterizados[mask_usuarios_max].copy()\n",
    "\n",
    "                # guardando información del modelo y de las cuentas \n",
    "\n",
    "                df_usuarios_analisis_clu_noclu = df_usuarios_analisis_pre_pro.merge(df_usuarios_analisis_clusterizados[['CUENTA','CLUSTER']],\n",
    "                                                                                 on='CUENTA', how='left')\n",
    "                df_usuarios_analisis_clu_noclu.fillna(value={'CLUSTER':-2}, inplace=True)\n",
    "\n",
    "                df_group = df_usuarios_analisis_clu_noclu.groupby(['CUENTA_MATRIZ','CLUSTER']).agg({'CUENTA':'count','traf_total':'sum'}).reset_index()\n",
    "\n",
    "                save_csv(df_usuarios_analisis_clu_noclu, f'{path_folder}/analysis_users.csv')\n",
    "                save_csv(df_group, f'{path_folder}/resumen_modelo.csv')\n",
    "\n",
    "                df_centroides = create_map_users_clusters(df_usuarios_analisis_clusterizados, path_folder, colors_list)\n",
    "                save_csv(df_centroides,  f'{path_folder}/centroides.csv')\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "time.time() -t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
